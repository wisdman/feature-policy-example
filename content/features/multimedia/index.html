<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
  <title>Feature-Policy Multimedia Demo</title>
  <link rel="stylesheet" type="text/css" href="/styles.css">
  <style type="text/css">
    body {
      display: flex;
      flex-wrap: wrap;
      align-items: stretch;
      align-content: flex-start;
    }

    main {
      flex: 0 0 100%;
    }

    video {
      width: 100px;
      height: 100px;
      margin: 0;
    }

    #analyser {
      background-color: var(--error-color);
      width: 100px;
      height: 100px;
      border-radius: 50%;
      margin-left: 16px;
      opacity: 0;
      transition: .2s opacity;
    }
  </style>
</head>
<body>
  <main></main>
  <video></video>
  <div id="analyser"></div>
  <script type="text/javascript">
    void async function() {
      const mainNode = document.querySelector("main")
      const LOG = (text, type) => mainNode.insertAdjacentHTML("beforeend", `<p class="${type}">${text}</p>`)

      if (ReportingObserver) {
        new ReportingObserver(reportList => {
          reportList.forEach(report => console.log(report))
        }, {"types": ["feature-policy-violation"]}).observe()
      }

      const video = document.querySelector("video")
      const analyserNode = document.querySelector("#analyser")

      let videoStream

      try {
        videoStream = await navigator.mediaDevices.getUserMedia({ video:true })
      } catch(error) {
        LOG(`Video Device access rejected<br>${error}`, "error")
      }

      if (videoStream) {
        LOG(`Video Device access granted`, "success")
        video.srcObject = videoStream
        video.play()
      }

      let audioStream

      try {
        audioStream = await navigator.mediaDevices.getUserMedia({ audio: true })

        const AudioContext = window.AudioContext || window.webkitAudioContext
        const audioContext = new AudioContext()

        const source = audioContext.createMediaStreamSource(audioStream)
        const analyser = audioContext.createScriptProcessor(1024, 1, 1)

        source.connect(audioContext.destination)
        source.connect(analyser)
        analyser.connect(audioContext.destination)

        analyser.addEventListener("audioprocess", event => {
          const level = event.inputBuffer.getChannelData(0).reduce( (m, v) => Math.max(m, v), 0)
          analyserNode.style.opacity = level
        })
      } catch(error) {
        LOG(`Audio Device access rejected<br>${error}`, "error")
      }

      if (audioStream) {
         LOG(`Audio Device access granted`, "success")
      }
    }()
  </script>
</body>
</html>